{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "scripts_dir = Path(\"D:/py/qlib/scripts\")\n",
    "print(scripts_dir.joinpath(\"get_data.py\"))\n",
    "assert scripts_dir.joinpath(\"get_data.py\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not scripts_dir.joinpath(\"get_data.py\").exists():\n",
    "    # download get_data.py script\n",
    "    scripts_dir = Path(\"~/tmp/qlib_code/scripts\").expanduser().resolve()\n",
    "    scripts_dir.mkdir(parents=True, exist_ok=True)\n",
    "    import requests\n",
    "    with requests.get(\"https://raw.githubusercontent.com/microsoft/qlib/main/scripts/get_data.py\") as resp:\n",
    "        with open(scripts_dir.joinpath(\"get_data.py\"), \"wb\") as fp:\n",
    "            fp.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.constant import REG_CN\n",
    "from qlib.utils import exists_qlib_data, init_instance_by_config\n",
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord\n",
    "from qlib.utils import flatten_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_uri = \"D:/py/qlib/.qlib/qlib_data/cn_data\"  # target_dir\n",
    "# if not exists_qlib_data(provider_uri):\n",
    "#     print(f\"Qlib data is not found in {provider_uri}\")\n",
    "#     sys.path.append(str(scripts_dir))\n",
    "#     from get_data import GetData\n",
    "#     GetData().qlib_data(target_dir=provider_uri, region=REG_CN)\n",
    "qlib.init(provider_uri=provider_uri, region=REG_CN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = \"csi300\"\n",
    "benchmark = \"SH000300\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data import D\n",
    "from qlib.data.filter import ExpressionDFilter\n",
    "from qlib.data.filter import NameDFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = D.instruments(market='csi300')\n",
    "fields = ['$close', '(Ref($close, -1)-$close)/$close', '(Ref($close, -2)-Ref($close, -1))/Ref($close, -1)', '(Ref($close, -3)-Ref($close, -2))/Ref($close, -2)', '(Ref($close, -4)-Ref($close, -3))/Ref($close, -3)', '(Ref($close, -5)-Ref($close, -4))/Ref($close, -4)', '(Ref($close, -6)-Ref($close, -5))/Ref($close, -5)', '(Ref($close, -7)-Ref($close, -6))/Ref($close, -6)']\n",
    "f_d = D.features(instruments, fields, start_time='2021-01-04', end_time='2021-06-11', freq='day')\n",
    "df = f_d\n",
    "df.index = df.index.get_level_values('datetime')\n",
    "print(df.index.min(), df.index.max())\n",
    "\n",
    "start_time = pd.to_datetime(df.index.min())\n",
    "end_time = pd.to_datetime(df.index.max())\n",
    "print(start_time.strftime('%Y-%m-%d'), end_time.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name=\"online_srv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# train model\n",
    "###################################\n",
    "# '2017-01-04', end_time='2022-02-28'\n",
    "data_handler_config = {\n",
    "    # \"start_time\": \"2017-01-04\",\n",
    "    \"start_time\": start_time, # \n",
    "    \"end_time\": end_time,\n",
    "    \"fit_start_time\": \"2021-01-04\",\n",
    "    \"fit_end_time\": \"2021-04-30\",\n",
    "    \"instruments\": market,\n",
    "    \"infer_processors\": [\n",
    "      {\n",
    "        \"class\": \"RobustZScoreNorm\",\n",
    "        \"kwargs\": {\n",
    "          \"fields_group\": \"feature\",\n",
    "          \"clip_outlier\": True\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"class\": \"Fillna\",\n",
    "        \"kwargs\": {\n",
    "          \"fields_group\": \"feature\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"learn_processors\": [\n",
    "      {\n",
    "        \"class\": \"DropnaLabel\"\n",
    "      },\n",
    "      {\n",
    "        \"class\": \"CSRankNorm\",\n",
    "        \"kwargs\": {\n",
    "          \"fields_group\": \"label\"\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"label\": [\n",
    "      \"Ref($close, -2) / Ref($close, -1) - 1\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "task = {   \n",
    "    \"model\": {\n",
    "        \"class\": \"LSTM\",\n",
    "        \"module_path\": \"qlib.contrib.model.pytorch_lstm\",\n",
    "        \"kwargs\": {\n",
    "            \"d_feat\": 6,\n",
    "            \"hidden_size\": 64,\n",
    "            \"num_layers\": 2,\n",
    "            \"dropout\": 0.1,\n",
    "            \"dec_dropout\": 0.0,\n",
    "            \"n_epochs\": 15,\n",
    "            \"lr\": 1e-5,\n",
    "            \"early_stop\": 3,\n",
    "            \"batch_size\": 800,\n",
    "            \"metric\": \"loss\",\n",
    "            \"loss\": \"mse\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"GPU\": 0\n",
    "        },\n",
    "    },\n",
    "    \"dataset\": {\n",
    "        \"class\": \"DatasetH\",\n",
    "        \"module_path\": \"qlib.data.dataset\",\n",
    "        \"kwargs\": {\n",
    "            \"handler\": {\n",
    "                \"class\": \"Alpha360\",\n",
    "                \"module_path\": \"qlib.contrib.data.handler\",\n",
    "                \"kwargs\": data_handler_config,\n",
    "            },\n",
    "            \"segments\": {\n",
    "                \"train\": (start_time, \"2021-04-30\"),\n",
    "                \"valid\": (\"2021-05-01\", \"2021-05-19\"),\n",
    "                \"test\": (\"2021-05-20\", \"2021-06-11\"),\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# model initiaiton\n",
    "model = init_instance_by_config(task[\"model\"])\n",
    "dataset = init_instance_by_config(task[\"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start exp to train model\n",
    "\n",
    "experiment_id = 'cn_backtest'\n",
    "# experiment_name: Optional[Text] = None,\n",
    "# recorder_id: Optional[Text] = None,\n",
    "\n",
    "# with R.start(experiment_name=experiment_name, experimen\n",
    "# t_id=experiment_id):\n",
    "with R.start(experiment_name=experiment_name):\n",
    "    R.log_params(**flatten_dict(task))\n",
    "    model.fit(dataset)\n",
    "    R.save_objects(trained_model=model)\n",
    "    rid = R.get_recorder().id\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[4030:4050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.load('pred.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.load('label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = PortAnaRecord(recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2021-05-17\",\n",
    "        \"end_time\": \"2021-06-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"online_srv\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position\n",
    "from qlib.data import D\n",
    "recorder = R.get_recorder(recorder_id=ba_rid, experiment_name=\"online_srv\")\n",
    "print(recorder)\n",
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "pred_df_dates = pred_df.index.get_level_values(level='datetime')\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_normal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright (c) Microsoft Corporation.\n",
    "#  Licensed under the MIT License.\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import Union, List, Optional\n",
    "\n",
    "from qlib.utils.exceptions import LoadObjectError\n",
    "from qlib.contrib.evaluate import risk_analysis, indicator_analysis\n",
    "\n",
    "from qlib.data.dataset import DatasetH\n",
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "from qlib.backtest import backtest as normal_backtest\n",
    "from qlib.log import get_module_logger\n",
    "from qlib.utils import fill_placeholder, flatten_dict, class_casting, get_date_by_shift\n",
    "from qlib.utils.time import Freq\n",
    "from qlib.utils.data import deepcopy_basic_type\n",
    "from qlib.contrib.eva.alpha import calc_ic, calc_long_short_return, calc_long_short_prec\n",
    "\n",
    "\n",
    "logger = get_module_logger(\"workflow\", logging.INFO)\n",
    "\n",
    "class RecordTemp:\n",
    "    \"\"\"\n",
    "    This is the Records Template class that enables user to generate experiment results such as IC and\n",
    "    backtest in a certain format.\n",
    "    \"\"\"\n",
    "\n",
    "    artifact_path = None\n",
    "    depend_cls = None  # the depend class of the record; the record will depend on the results generated by `depend_cls`\n",
    "\n",
    "    @classmethod\n",
    "    def get_path(cls, path=None):\n",
    "        names = []\n",
    "        if cls.artifact_path is not None:\n",
    "            names.append(cls.artifact_path)\n",
    "\n",
    "        if path is not None:\n",
    "            names.append(path)\n",
    "\n",
    "        return \"/\".join(names)\n",
    "\n",
    "    def save(self, **kwargs):\n",
    "        \"\"\"\n",
    "        It behaves the same as self.recorder.save_objects.\n",
    "        But it is an easier interface because users don't have to care about `get_path` and `artifact_path`\n",
    "        \"\"\"\n",
    "        art_path = self.get_path()\n",
    "        if art_path == \"\":\n",
    "            art_path = None\n",
    "        self.recorder.save_objects(artifact_path=art_path, **kwargs)\n",
    "\n",
    "    def __init__(self, recorder):\n",
    "        self._recorder = recorder\n",
    "\n",
    "    @property\n",
    "    def recorder(self):\n",
    "        if self._recorder is None:\n",
    "            raise ValueError(\"This RecordTemp did not set recorder yet.\")\n",
    "        return self._recorder\n",
    "\n",
    "    def generate(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate certain records such as IC, backtest etc., and save them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        kwargs\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(f\"Please implement the `generate` method.\")\n",
    "\n",
    "    def load(self, name: str, parents: bool = True):\n",
    "        \"\"\"\n",
    "        It behaves the same as self.recorder.load_object.\n",
    "        But it is an easier interface because users don't have to care about `get_path` and `artifact_path`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            the name for the file to be load.\n",
    "\n",
    "        parents : bool\n",
    "            Each recorder has different `artifact_path`.\n",
    "            So parents recursively find the path in parents\n",
    "            Sub classes has higher priority\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        The stored records.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.recorder.load_object(self.get_path(name))\n",
    "        except LoadObjectError:\n",
    "            if parents:\n",
    "                if self.depend_cls is not None:\n",
    "                    with class_casting(self, self.depend_cls):\n",
    "                        return self.load(name, parents=True)\n",
    "\n",
    "    def list(self):\n",
    "        \"\"\"\n",
    "        List the supported artifacts.\n",
    "        Users don't have to consider self.get_path\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        A list of all the supported artifacts.\n",
    "        \"\"\"\n",
    "        return []\n",
    "\n",
    "    def check(self, include_self: bool = False, parents: bool = True):\n",
    "        \"\"\"\n",
    "        Check if the records is properly generated and saved.\n",
    "        It is useful in following examples\n",
    "        - checking if the depended files complete before generating new things.\n",
    "        - checking if the final files is completed\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        include_self : bool\n",
    "            is the file generated by self included\n",
    "        parents : bool\n",
    "            will we check parents\n",
    "\n",
    "        Raise\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "        : whether the records are stored properly.\n",
    "        \"\"\"\n",
    "        if include_self:\n",
    "\n",
    "            # Some mlflow backend will not list the directly recursively.\n",
    "            # So we force to the directly\n",
    "            artifacts = {}\n",
    "\n",
    "            def _get_arts(dirn):\n",
    "                if dirn not in artifacts:\n",
    "                    artifacts[dirn] = self.recorder.list_artifacts(dirn)\n",
    "                return artifacts[dirn]\n",
    "\n",
    "            for item in self.list():\n",
    "                ps = self.get_path(item).split(\"/\")\n",
    "                dirn, fn = \"/\".join(ps[:-1]), ps[-1]\n",
    "                if self.get_path(item) not in _get_arts(dirn):\n",
    "                    raise FileNotFoundError\n",
    "        if parents:\n",
    "            if self.depend_cls is not None:\n",
    "                with class_casting(self, self.depend_cls):\n",
    "                    self.check(include_self=True)\n",
    "\n",
    "\n",
    "class ACRecordTemp(RecordTemp):\n",
    "    \"\"\"Automatically checking record template\"\"\"\n",
    "\n",
    "    def __init__(self, recorder, skip_existing=False):\n",
    "        self.skip_existing = skip_existing\n",
    "        super().__init__(recorder=recorder)\n",
    "\n",
    "    def generate(self, *args, **kwargs):\n",
    "        \"\"\"automatically checking the files and then run the concrete generating task\"\"\"\n",
    "        if self.skip_existing:\n",
    "            try:\n",
    "                self.check(include_self=True, parents=False)\n",
    "            except FileNotFoundError:\n",
    "                pass  # continue to generating metrics\n",
    "            else:\n",
    "                logger.info(\"The results has previously generated, Generation skipped.\")\n",
    "                return\n",
    "\n",
    "        try:\n",
    "            self.check()\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(\"The dependent data does not exists. Generation skipped.\")\n",
    "            return\n",
    "        return self._generate(*args, **kwargs)\n",
    "\n",
    "    def _generate(self, *args, **kwargs):\n",
    "        raise NotImplementedError(f\"Please implement the `_generate` method\")\n",
    "\n",
    "\n",
    "class PortAnaRecord(ACRecordTemp):\n",
    "    \"\"\"\n",
    "    This is the Portfolio Analysis Record class that generates the analysis results such as those of backtest. This class inherits the ``RecordTemp`` class.\n",
    "\n",
    "    The following files will be stored in recorder\n",
    "    - report_normal.pkl & positions_normal.pkl:\n",
    "        - The return report and detailed positions of the backtest, returned by `qlib/contrib/evaluate.py:backtest`\n",
    "    - port_analysis.pkl : The risk analysis of your portfolio, returned by `qlib/contrib/evaluate.py:risk_analysis`\n",
    "    \"\"\"\n",
    "\n",
    "    artifact_path = \"portfolio_analysis\"\n",
    "    depend_cls = SignalRecord\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        recorder,\n",
    "        config=None,\n",
    "        risk_analysis_freq: Union[List, str] = None,\n",
    "        indicator_analysis_freq: Union[List, str] = None,\n",
    "        indicator_analysis_method=None,\n",
    "        skip_existing=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        config[\"strategy\"] : dict\n",
    "            define the strategy class as well as the kwargs.\n",
    "        config[\"executor\"] : dict\n",
    "            define the executor class as well as the kwargs.\n",
    "        config[\"backtest\"] : dict\n",
    "            define the backtest kwargs.\n",
    "        risk_analysis_freq : str|List[str]\n",
    "            risk analysis freq of report\n",
    "        indicator_analysis_freq : str|List[str]\n",
    "            indicator analysis freq of report\n",
    "        indicator_analysis_method : str, optional, default by None\n",
    "            the candidated values include 'mean', 'amount_weighted', 'value_weighted'\n",
    "        \"\"\"\n",
    "        super().__init__(recorder=recorder, skip_existing=skip_existing, **kwargs)\n",
    "\n",
    "        if config is None:\n",
    "            config = {  # Default config for daily trading\n",
    "                \"strategy\": {\n",
    "                    \"class\": \"TopkDropoutStrategy\",\n",
    "                    \"module_path\": \"qlib.contrib.strategy\",\n",
    "                    \"kwargs\": {\"signal\": \"<PRED>\", \"topk\": 50, \"n_drop\": 5},\n",
    "                },\n",
    "                \"backtest\": {\n",
    "                    \"start_time\": None,\n",
    "                    \"end_time\": None,\n",
    "                    \"account\": 100000000,\n",
    "                    \"benchmark\": \"SH000300\",\n",
    "                    \"exchange_kwargs\": {\n",
    "                        \"limit_threshold\": 0.095,\n",
    "                        \"deal_price\": \"close\",\n",
    "                        \"open_cost\": 0.0005,\n",
    "                        \"close_cost\": 0.0015,\n",
    "                        \"min_cost\": 5,\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        # We only deepcopy_basic_type because\n",
    "        # - We don't want to affect the config outside.\n",
    "        # - We don't want to deepcopy complex object to avoid overhead\n",
    "        config = deepcopy_basic_type(config)\n",
    "\n",
    "        self.strategy_config = config[\"strategy\"]\n",
    "        _default_executor_config = {\n",
    "            \"class\": \"SimulatorExecutor\",\n",
    "            \"module_path\": \"qlib.backtest.executor\",\n",
    "            \"kwargs\": {\n",
    "                \"time_per_step\": \"day\",\n",
    "                \"generate_portfolio_metrics\": True,\n",
    "            },\n",
    "        }\n",
    "        self.executor_config = config.get(\"executor\", _default_executor_config)\n",
    "        self.backtest_config = config[\"backtest\"]\n",
    "\n",
    "        self.all_freq = self._get_report_freq(self.executor_config)\n",
    "        if risk_analysis_freq is None:\n",
    "            risk_analysis_freq = [self.all_freq[0]]\n",
    "        if indicator_analysis_freq is None:\n",
    "            indicator_analysis_freq = [self.all_freq[0]]\n",
    "\n",
    "        if isinstance(risk_analysis_freq, str):\n",
    "            risk_analysis_freq = [risk_analysis_freq]\n",
    "        if isinstance(indicator_analysis_freq, str):\n",
    "            indicator_analysis_freq = [indicator_analysis_freq]\n",
    "\n",
    "        self.risk_analysis_freq = [\n",
    "            \"{0}{1}\".format(*Freq.parse(_analysis_freq)) for _analysis_freq in risk_analysis_freq\n",
    "        ]\n",
    "        self.indicator_analysis_freq = [\n",
    "            \"{0}{1}\".format(*Freq.parse(_analysis_freq)) for _analysis_freq in indicator_analysis_freq\n",
    "        ]\n",
    "        self.indicator_analysis_method = indicator_analysis_method\n",
    "\n",
    "    def _get_report_freq(self, executor_config):\n",
    "        ret_freq = []\n",
    "        if executor_config[\"kwargs\"].get(\"generate_portfolio_metrics\", False):\n",
    "            _count, _freq = Freq.parse(executor_config[\"kwargs\"][\"time_per_step\"])\n",
    "            ret_freq.append(f\"{_count}{_freq}\")\n",
    "        if \"inner_executor\" in executor_config[\"kwargs\"]:\n",
    "            ret_freq.extend(self._get_report_freq(executor_config[\"kwargs\"][\"inner_executor\"]))\n",
    "        return ret_freq\n",
    "\n",
    "    def _generate(self, **kwargs):\n",
    "        pred = self.load(\"pred.pkl\")\n",
    "\n",
    "        # replace the \"<PRED>\" with prediction saved before\n",
    "        placehorder_value = {\"<PRED>\": pred}\n",
    "        for k in \"executor_config\", \"strategy_config\":\n",
    "            setattr(self, k, fill_placeholder(getattr(self, k), placehorder_value))\n",
    "\n",
    "        # if the backtesting time range is not set, it will automatically extract time range from the prediction file\n",
    "        dt_values = pred.index.get_level_values(\"datetime\")\n",
    "        if self.backtest_config[\"start_time\"] is None:\n",
    "            self.backtest_config[\"start_time\"] = dt_values.min()\n",
    "        if self.backtest_config[\"end_time\"] is None:\n",
    "            self.backtest_config[\"end_time\"] = get_date_by_shift(dt_values.max(), 1)\n",
    "\n",
    "        # custom strategy and get backtest\n",
    "        portfolio_metric_dict, indicator_dict = normal_backtest(\n",
    "            executor=self.executor_config, strategy=self.strategy_config, **self.backtest_config\n",
    "        )\n",
    "        for _freq, (report_normal, positions_normal) in portfolio_metric_dict.items():\n",
    "            self.save(**{f\"report_normal_{_freq}.pkl\": report_normal})\n",
    "            self.save(**{f\"positions_normal_{_freq}.pkl\": positions_normal})\n",
    "\n",
    "        for _freq, indicators_normal in indicator_dict.items():\n",
    "            self.save(**{f\"indicators_normal_{_freq}.pkl\": indicators_normal})\n",
    "\n",
    "        for _analysis_freq in self.risk_analysis_freq:\n",
    "            if _analysis_freq not in portfolio_metric_dict:\n",
    "                warnings.warn(\n",
    "                    f\"the freq {_analysis_freq} report is not found, please set the corresponding env with `generate_portfolio_metrics=True`\"\n",
    "                )\n",
    "            else:\n",
    "                report_normal, _ = portfolio_metric_dict.get(_analysis_freq)\n",
    "                analysis = dict()\n",
    "                analysis[\"excess_return_without_cost\"] = risk_analysis(\n",
    "                    report_normal[\"return\"] - report_normal[\"bench\"], freq=_analysis_freq\n",
    "                )\n",
    "                analysis[\"excess_return_with_cost\"] = risk_analysis(\n",
    "                    report_normal[\"return\"] - report_normal[\"bench\"] - report_normal[\"cost\"], freq=_analysis_freq\n",
    "                )\n",
    "\n",
    "                analysis_df = pd.concat(analysis)  # type: pd.DataFrame\n",
    "                # log metrics\n",
    "                analysis_dict = flatten_dict(analysis_df[\"risk\"].unstack().T.to_dict())\n",
    "                self.recorder.log_metrics(**{f\"{_analysis_freq}.{k}\": v for k, v in analysis_dict.items()})\n",
    "                # save results\n",
    "                self.save(**{f\"port_analysis_{_analysis_freq}.pkl\": analysis_df})\n",
    "                logger.info(\n",
    "                    f\"Portfolio analysis record 'port_analysis_{_analysis_freq}.pkl' has been saved as the artifact of the Experiment {self.recorder.experiment_id}\"\n",
    "                )\n",
    "                # print out results\n",
    "                pprint(f\"The following are analysis results of benchmark return({_analysis_freq}).\")\n",
    "                pprint(risk_analysis(report_normal[\"bench\"], freq=_analysis_freq))\n",
    "                pprint(f\"The following are analysis results of the excess return without cost({_analysis_freq}).\")\n",
    "                pprint(analysis[\"excess_return_without_cost\"])\n",
    "                pprint(f\"The following are analysis results of the excess return with cost({_analysis_freq}).\")\n",
    "                pprint(analysis[\"excess_return_with_cost\"])\n",
    "\n",
    "        for _analysis_freq in self.indicator_analysis_freq:\n",
    "            if _analysis_freq not in indicator_dict:\n",
    "                warnings.warn(f\"the freq {_analysis_freq} indicator is not found\")\n",
    "            else:\n",
    "                indicators_normal = indicator_dict.get(_analysis_freq)\n",
    "                if self.indicator_analysis_method is None:\n",
    "                    analysis_df = indicator_analysis(indicators_normal)\n",
    "                else:\n",
    "                    analysis_df = indicator_analysis(indicators_normal, method=self.indicator_analysis_method)\n",
    "                # log metrics\n",
    "                analysis_dict = analysis_df[\"value\"].to_dict()\n",
    "                self.recorder.log_metrics(**{f\"{_analysis_freq}.{k}\": v for k, v in analysis_dict.items()})\n",
    "                # save results\n",
    "                self.save(**{f\"indicator_analysis_{_analysis_freq}.pkl\": analysis_df})\n",
    "                logger.info(\n",
    "                    f\"Indicator analysis record 'indicator_analysis_{_analysis_freq}.pkl' has been saved as the artifact of the Experiment {self.recorder.experiment_id}\"\n",
    "                )\n",
    "                pprint(f\"The following are analysis results of indicators({_analysis_freq}).\")\n",
    "                pprint(analysis_df)\n",
    "\n",
    "    def list(self):\n",
    "        list_path = []\n",
    "        for _freq in self.all_freq:\n",
    "            list_path.extend(\n",
    "                [\n",
    "                    f\"report_normal_{_freq}.pkl\",\n",
    "                    f\"positions_normal_{_freq}.pkl\",\n",
    "                ]\n",
    "            )\n",
    "        for _analysis_freq in self.risk_analysis_freq:\n",
    "            if _analysis_freq in self.all_freq:\n",
    "                list_path.append(f\"port_analysis_{_analysis_freq}.pkl\")\n",
    "            else:\n",
    "                warnings.warn(f\"risk_analysis freq {_analysis_freq} is not found\")\n",
    "\n",
    "        for _analysis_freq in self.indicator_analysis_freq:\n",
    "            if _analysis_freq in self.all_freq:\n",
    "                list_path.append(f\"indicator_analysis_{_analysis_freq}.pkl\")\n",
    "            else:\n",
    "                warnings.warn(f\"indicator_analysis freq {_analysis_freq} is not found\")\n",
    "        return list_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"WeekTopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2021-05-20\",\n",
    "        \"end_time\": \"2021-06-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": benchmark,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=\"backtest_analysis\"):\n",
    "    recorder = R.get_recorder(recorder_id=rid, experiment_name=\"online_srv\")\n",
    "    model = recorder.load_object(\"trained_model\")\n",
    "\n",
    "    # prediction\n",
    "    recorder = R.get_recorder()\n",
    "    ba_rid = recorder.id\n",
    "    sr = SignalRecord(model, dataset, recorder)\n",
    "    sr.generate()\n",
    "\n",
    "    # backtest & analysis\n",
    "    par = PortAnaRecord(recorder, port_analysis_config, \"day\")\n",
    "    par.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from qlib.backtest.signal import Signal, create_signal_from\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Dict, List, Text, Tuple, Union\n",
    "\n",
    "from qlib.data import D\n",
    "from qlib.data.dataset import Dataset\n",
    "from qlib.model.base import BaseModel\n",
    "from qlib.strategy.base import BaseStrategy\n",
    "from qlib.backtest.position import Position\n",
    "from qlib.backtest.decision import Order, OrderDir, TradeDecisionWO\n",
    "from qlib.log import get_module_logger\n",
    "from qlib.utils import get_pre_trading_date, load_dataset\n",
    "from qlib.contrib.strategy.order_generator import OrderGenWOInteract\n",
    "from qlib.contrib.strategy.optimizer import EnhancedIndexingOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSignalStrategy(BaseStrategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        signal: Union[Signal, Tuple[BaseModel, Dataset], List, Dict, Text, pd.Series, pd.DataFrame] = None,\n",
    "        model=None,\n",
    "        dataset=None,\n",
    "        risk_degree: float = 0.95,\n",
    "        trade_exchange=None,\n",
    "        level_infra=None,\n",
    "        common_infra=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        signal :\n",
    "            the information to describe a signal. Please refer to the docs of `qlib.backtest.signal.create_signal_from`\n",
    "            the decision of the strategy will base on the given signal\n",
    "        risk_degree : float\n",
    "            position percentage of total value.\n",
    "        trade_exchange : Exchange\n",
    "            exchange that provides market info, used to deal order and generate report\n",
    "            - If `trade_exchange` is None, self.trade_exchange will be set with common_infra\n",
    "            - It allowes different trade_exchanges is used in different executions.\n",
    "            - For example:\n",
    "                - In daily execution, both daily exchange and minutely are usable, but the daily exchange is recommended because it run faster.\n",
    "                - In minutely execution, the daily exchange is not usable, only the minutely exchange is recommended.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(level_infra=level_infra, common_infra=common_infra, trade_exchange=trade_exchange, **kwargs)\n",
    "\n",
    "        self.risk_degree = risk_degree\n",
    "\n",
    "        # This is trying to be compatible with previous version of qlib task config\n",
    "        if model is not None and dataset is not None:\n",
    "            warnings.warn(\"`model` `dataset` is deprecated; use `signal`.\", DeprecationWarning)\n",
    "            signal = model, dataset\n",
    "\n",
    "        self.signal: Signal = create_signal_from(signal)\n",
    "\n",
    "    def get_risk_degree(self, trade_step=None):\n",
    "        \"\"\"get_risk_degree\n",
    "        Return the proportion of your total value you will used in investment.\n",
    "        Dynamically risk_degree will result in Market timing.\n",
    "        \"\"\"\n",
    "        # It will use 95% amount of your total value by default\n",
    "        return self.risk_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class WeekTopkDropoutStrategy(BaseSignalStrategy):\n",
    "    # TODO:\n",
    "    # 1. Supporting leverage the get_range_limit result from the decision\n",
    "    # 2. Supporting alter_outer_trade_decision\n",
    "    # 3. Supporting checking the availability of trade decision\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            topk,\n",
    "            n_drop,\n",
    "            method_sell=\"bottom\",\n",
    "            method_buy=\"top\",\n",
    "            hold_thresh=1,\n",
    "            only_tradable=False,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        topk : int\n",
    "            the number of stocks in the portfolio.\n",
    "        n_drop : int\n",
    "            number of stocks to be replaced in each trading date.\n",
    "        method_sell : str\n",
    "            dropout method_sell, random/bottom.\n",
    "        method_buy : str\n",
    "            dropout method_buy, random/top.\n",
    "        hold_thresh : int\n",
    "            minimum holding days\n",
    "            before sell stock , will check current.get_stock_count(order.stock_id) >= self.hold_thresh.\n",
    "        only_tradable : bool\n",
    "            will the strategy only consider the tradable stock when buying and selling.\n",
    "            if only_tradable:\n",
    "                strategy will make buy sell decision without checking the tradable state of the stock.\n",
    "            else:\n",
    "                strategy will make decision with the tradable state of the stock info and avoid buy and sell them.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.topk = topk\n",
    "        self.n_drop = n_drop\n",
    "        self.method_sell = method_sell\n",
    "        self.method_buy = method_buy\n",
    "        self.hold_thresh = hold_thresh\n",
    "        self.only_tradable = only_tradable\n",
    "\n",
    "    \n",
    "\n",
    "    def generate_trade_decision(self, execute_result=None):\n",
    "        # get the number of trading step finished, trade_step can be [0, 1, 2, ..., trade_len - 1]\n",
    "        trade_step = self.trade_calendar.get_trade_step()\n",
    "        trade_start_time, trade_end_time = self.trade_calendar.get_step_time(trade_step)\n",
    "        pred_start_time, pred_end_time = self.trade_calendar.get_step_time(trade_step, shift=-1)\n",
    "        pred_score = self.signal.get_signal(start_time=pred_start_time, end_time=pred_end_time)\n",
    "        print(trade_start_time, trade_end_time, pred_start_time, pred_end_time, trade_step)\n",
    "        print(pred_score)\n",
    "\n",
    "        def get_week_HighAndLow(datetime, instruments):\n",
    "            # 计算一周后的涨跌幅\n",
    "            # instruments = D.instruments(market='all')\n",
    "            datetime = datetime.strftime('%Y-%m-%d')\n",
    "            fields = ['(Ref($close, -1)-$close)/$close', '(Ref($close, -2)-Ref($close, -1))/Ref($close, -1)',\n",
    "                      '(Ref($close, -3)-Ref($close, -2))/Ref($close, -2)',\n",
    "                      '(Ref($close, -4)-Ref($close, -3))/Ref($close, -3)',\n",
    "                      '(Ref($close, -5)-Ref($close, -4))/Ref($close, -4)',\n",
    "                      '(Ref($close, -6)-Ref($close, -5))/Ref($close, -5)',\n",
    "                      '(Ref($close, -7)-Ref($close, -6))/Ref($close, -6)']\n",
    "            f_d = D.features(instruments, fields, start_time='2021-05-20', end_time='2021-06-11', freq='day')\n",
    "            wha = f_d.loc[(slice(None), datetime), :]\n",
    "            wha['A_Week_HighAndLow'] = wha.apply(lambda x: x.sum(), axis=1)\n",
    "            wha = wha.loc[:, 'A_Week_HighAndLow'].droplevel('datetime')\n",
    "            return wha\n",
    "\n",
    "        wha = get_week_HighAndLow(datetime=pred_start_time, instruments=D.instruments(\"all\"))\n",
    "        \n",
    "        print(wha)\n",
    "        pred = pd.concat([wha, pred_score], axis=1)\n",
    "        pred.columns = ['A_Week_HighAndLow', 'score']\n",
    "\n",
    "        def compute_score(a, b):\n",
    "            # a是wha，b是pred_score\n",
    "            return a * (2 / 3) + b * (1 / 3)\n",
    "\n",
    "        pred['value'] = pred.apply(lambda row: compute_score(row['A_Week_HighAndLow'], row['score']), axis=1)\n",
    "        pred_score = pred['value']\n",
    "\n",
    "        # NOTE: the current version of topk dropout strategy can't handle pd.DataFrame(multiple signal)\n",
    "        # So it only leverage the first col of signal\n",
    "\n",
    "        if isinstance(pred_score, pd.DataFrame):\n",
    "            pred_score = pred_score.iloc[:, 0]\n",
    "        if pred_score is None:\n",
    "            print(\"pred_score is None\")\n",
    "            # print(trade_step, trade_start_time, trade_end_time)\n",
    "            # print(pred_start_time, pred_end_time)\n",
    "            return TradeDecisionWO([], self)\n",
    "        if self.only_tradable:\n",
    "            # If The strategy only consider tradable stock when make decision\n",
    "            # It needs following actions to filter stocks\n",
    "            def get_first_n(l, n, reverse=False):\n",
    "                cur_n = 0\n",
    "                res = []\n",
    "                for si in reversed(l) if reverse else l:\n",
    "                    if self.trade_exchange.is_stock_tradable(\n",
    "                            stock_id=si, start_time=trade_start_time, end_time=trade_end_time\n",
    "                    ):\n",
    "                        res.append(si)\n",
    "                        cur_n += 1\n",
    "                        if cur_n >= n:\n",
    "                            break\n",
    "                return res[::-1] if reverse else res\n",
    "\n",
    "            def get_last_n(l, n):\n",
    "                return get_first_n(l, n, reverse=True)\n",
    "\n",
    "            def filter_stock(l):\n",
    "                return [\n",
    "                    si\n",
    "                    for si in l\n",
    "                    if self.trade_exchange.is_stock_tradable(\n",
    "                        stock_id=si, start_time=trade_start_time, end_time=trade_end_time\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "        else:\n",
    "            # Otherwise, the stock will make decision with out the stock tradable info\n",
    "            def get_first_n(l, n):\n",
    "                return list(l)[:n]\n",
    "\n",
    "            def get_last_n(l, n):\n",
    "                return list(l)[-n:]\n",
    "\n",
    "            def filter_stock(l):\n",
    "                return l\n",
    "\n",
    "        current_temp = copy.deepcopy(self.trade_position)\n",
    "        # generate order list for this adjust date\n",
    "        sell_order_list = []\n",
    "        buy_order_list = []\n",
    "        # load score\n",
    "        cash = current_temp.get_cash()\n",
    "        current_stock_list = current_temp.get_stock_list()\n",
    "        # last position (sorted by score)\n",
    "        last = pred_score.reindex(current_stock_list).sort_values(ascending=False).index\n",
    "        # The new stocks today want to buy **at most**\n",
    "        if self.method_buy == \"top\":\n",
    "            today = get_first_n(\n",
    "                pred_score[~pred_score.index.isin(last)].sort_values(ascending=False).index,\n",
    "                self.n_drop + self.topk - len(last),\n",
    "            )\n",
    "        elif self.method_buy == \"random\":\n",
    "            topk_candi = get_first_n(pred_score.sort_values(ascending=False).index, self.topk)\n",
    "            candi = list(filter(lambda x: x not in last, topk_candi))\n",
    "            n = self.n_drop + self.topk - len(last)\n",
    "            try:\n",
    "                today = np.random.choice(candi, n, replace=False)\n",
    "            except ValueError:\n",
    "                today = candi\n",
    "        else:\n",
    "            raise NotImplementedError(f\"This type of input is not supported\")\n",
    "        # combine(new stocks + last stocks),  we will drop stocks from this list\n",
    "        # In case of dropping higher score stock and buying lower score stock.\n",
    "        comb = pred_score.reindex(last.union(pd.Index(today))).sort_values(ascending=False).index\n",
    "\n",
    "        # Get the stock list we really want to sell (After filtering the case that we sell high and buy low)\n",
    "        if self.method_sell == \"bottom\":\n",
    "            sell = last[last.isin(get_last_n(comb, self.n_drop))]\n",
    "        elif self.method_sell == \"random\":\n",
    "            candi = filter_stock(last)\n",
    "            try:\n",
    "                sell = pd.Index(np.random.choice(candi, self.n_drop, replace=False) if len(last) else [])\n",
    "            except ValueError:  # No enough candidates\n",
    "                sell = candi\n",
    "        else:\n",
    "            raise NotImplementedError(f\"This type of input is not supported\")\n",
    "\n",
    "        # Get the stock list we really want to buy\n",
    "        buy = today[: len(sell) + self.topk - len(last)]\n",
    "        for code in current_stock_list:\n",
    "            if not self.trade_exchange.is_stock_tradable(\n",
    "                    stock_id=code, start_time=trade_start_time, end_time=trade_end_time\n",
    "            ):\n",
    "                continue\n",
    "            if code in sell:\n",
    "                # check hold limit\n",
    "                time_per_step = self.trade_calendar.get_freq()\n",
    "                if current_temp.get_stock_count(code, bar=time_per_step) < self.hold_thresh:\n",
    "                    continue\n",
    "                # sell order\n",
    "                sell_amount = current_temp.get_stock_amount(code=code)\n",
    "                factor = self.trade_exchange.get_factor(\n",
    "                    stock_id=code, start_time=trade_start_time, end_time=trade_end_time\n",
    "                )\n",
    "                # sell_amount = self.trade_exchange.round_amount_by_trade_unit(sell_amount, factor)\n",
    "                sell_order = Order(\n",
    "                    stock_id=code,\n",
    "                    amount=sell_amount,\n",
    "                    start_time=trade_start_time,\n",
    "                    end_time=trade_end_time,\n",
    "                    direction=Order.SELL,  # 0 for sell, 1 for buy\n",
    "                )\n",
    "                # is order executable\n",
    "                if self.trade_exchange.check_order(sell_order):\n",
    "                    sell_order_list.append(sell_order)\n",
    "                    trade_val, trade_cost, trade_price = self.trade_exchange.deal_order(\n",
    "                        sell_order, position=current_temp\n",
    "                    )\n",
    "                    # update cash\n",
    "                    cash += trade_val - trade_cost\n",
    "        # buy new stock\n",
    "        # note the current has been changed\n",
    "        current_stock_list = current_temp.get_stock_list()\n",
    "        value = cash * self.risk_degree / len(buy) if len(buy) > 0 else 0\n",
    "\n",
    "        # open_cost should be considered in the real trading environment, while the backtest in evaluate.py does not\n",
    "        # consider it as the aim of demo is to accomplish same strategy as evaluate.py, so comment out this line\n",
    "        # value = value / (1+self.trade_exchange.open_cost) # set open_cost limit\n",
    "        for code in buy:\n",
    "            # check is stock suspended\n",
    "            if not self.trade_exchange.is_stock_tradable(\n",
    "                    stock_id=code, start_time=trade_start_time, end_time=trade_end_time\n",
    "            ):\n",
    "                continue\n",
    "            # buy order\n",
    "            buy_price = self.trade_exchange.get_deal_price(\n",
    "                stock_id=code, start_time=trade_start_time, end_time=trade_end_time, direction=OrderDir.BUY\n",
    "            )\n",
    "            buy_amount = value / buy_price\n",
    "            factor = self.trade_exchange.get_factor(stock_id=code, start_time=trade_start_time, end_time=trade_end_time)\n",
    "            buy_amount = self.trade_exchange.round_amount_by_trade_unit(buy_amount, factor)\n",
    "            buy_order = Order(\n",
    "                stock_id=code,\n",
    "                amount=buy_amount,\n",
    "                start_time=trade_start_time,\n",
    "                end_time=trade_end_time,\n",
    "                direction=Order.BUY,  # 1 for buy\n",
    "            )\n",
    "            buy_order_list.append(buy_order)\n",
    "        return TradeDecisionWO(sell_order_list + buy_order_list, self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft Corporation.\n",
    "# Licensed under the MIT License.\n",
    "from __future__ import annotations\n",
    "import copy\n",
    "from typing import List, Tuple, Union, TYPE_CHECKING\n",
    "\n",
    "from qlib.backtest.account import Account\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from qlib.strategy.base import BaseStrategy\n",
    "    from qlib.backtest.executor import BaseExecutor\n",
    "    from qlib.backtest.decision import BaseTradeDecision\n",
    "from qlib.backtest.position import Position\n",
    "from qlib.backtest.exchange import Exchange\n",
    "from qlib.backtest.backtest import backtest_loop\n",
    "from qlib.backtest.backtest import collect_data_loop\n",
    "from qlib.backtest.utils import CommonInfrastructure\n",
    "from qlib.backtest.decision import Order\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.log import get_module_logger\n",
    "from qlib.config import C\n",
    "\n",
    "\n",
    "def create_account_instance(\n",
    "    start_time, end_time, benchmark: str, account: Union[float, int, dict], pos_type: str = \"Position\"\n",
    ") -> Account:\n",
    "    \"\"\"\n",
    "    # TODO: is very strange pass benchmark_config in the account(maybe for report)\n",
    "    # There should be a post-step to process the report.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_time\n",
    "        start time of the benchmark\n",
    "    end_time\n",
    "        end time of the benchmark\n",
    "    benchmark : str\n",
    "        the benchmark for reporting\n",
    "    account :   Union[\n",
    "                    float,\n",
    "                    {\n",
    "                        \"cash\": float,\n",
    "                        \"stock1\": Union[\n",
    "                                        int,    # it is equal to {\"amount\": int}\n",
    "                                        {\"amount\": int, \"price\"(optional): float},\n",
    "                                  ]\n",
    "                    },\n",
    "                ]\n",
    "        information for describing how to creating the account\n",
    "        For `float`:\n",
    "            Using Account with only initial cash\n",
    "        For `dict`:\n",
    "            key \"cash\" means initial cash.\n",
    "            key \"stock1\" means the information of first stock with amount and price(optional).\n",
    "            ...\n",
    "    \"\"\"\n",
    "    if isinstance(account, (int, float)):\n",
    "        pos_kwargs = {\"init_cash\": account}\n",
    "    elif isinstance(account, dict):\n",
    "        init_cash = account[\"cash\"]\n",
    "        del account[\"cash\"]\n",
    "        pos_kwargs = {\n",
    "            \"init_cash\": init_cash,\n",
    "            \"position_dict\": account,\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"account must be in (int, float, Position)\")\n",
    "\n",
    "    kwargs = {\n",
    "        \"init_cash\": account,\n",
    "        \"benchmark_config\": {\n",
    "            \"benchmark\": benchmark,\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "        },\n",
    "        \"pos_type\": pos_type,\n",
    "    }\n",
    "    kwargs.update(pos_kwargs)\n",
    "    return Account(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.backtest.utils import CommonInfrastructure\n",
    "from qlib.strategy.base import BaseStrategy  # pylint: disable=C0415\n",
    "from qlib.backtest.executor import BaseExecutor  # pylint: disable=C0415\n",
    "from qlib.backtest import get_exchange\n",
    "\n",
    "\n",
    "trade_account = create_account_instance(\n",
    "        start_time=start_time, end_time='2021-06-11', benchmark=benchmark, account=1e9, pos_type=\"Position\"\n",
    "    )\n",
    "\n",
    "exchange_kwargs: dict = {}\n",
    "exchange_kwargs = copy.copy(exchange_kwargs)\n",
    "if \"start_time\" not in exchange_kwargs:\n",
    "    exchange_kwargs[\"start_time\"] = start_time\n",
    "if \"end_time\" not in exchange_kwargs:\n",
    "    exchange_kwargs[\"end_time\"] = '2021-06-11'\n",
    "trade_exchange = get_exchange(**exchange_kwargs)\n",
    "\n",
    "common_infra = CommonInfrastructure(trade_account=trade_account, trade_exchange=trade_exchange)\n",
    "print(type(common_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import copy\n",
    "from qlib.backtest.position import BasePosition\n",
    "from qlib.log import get_module_logger\n",
    "from types import GeneratorType\n",
    "from qlib.backtest.account import Account\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "from qlib.backtest.decision import Order, BaseTradeDecision\n",
    "from qlib.backtest.exchange import Exchange\n",
    "from qlib.backtest.utils import TradeCalendarManager, CommonInfrastructure, LevelInfrastructure, get_start_end_idx\n",
    "\n",
    "from qlib.utils import init_instance_by_config\n",
    "from qlib.strategy.base import BaseStrategy\n",
    "\n",
    "\n",
    "class BaseExecutor:\n",
    "    \"\"\"Base executor for trading\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_per_step: str,\n",
    "        start_time: Union[str, pd.Timestamp] = None,\n",
    "        end_time: Union[str, pd.Timestamp] = None,\n",
    "        indicator_config: dict = {},\n",
    "        generate_portfolio_metrics: bool = False,\n",
    "        verbose: bool = False,\n",
    "        track_data: bool = False,\n",
    "        trade_exchange: Exchange = None,\n",
    "        common_infra: CommonInfrastructure = None,\n",
    "        settle_type=BasePosition.ST_NO,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        time_per_step : str\n",
    "            trade time per trading step, used for generate the trade calendar\n",
    "        show_indicator: bool, optional\n",
    "            whether to show indicators, :\n",
    "            - 'pa', the price advantage\n",
    "            - 'pos', the positive rate\n",
    "            - 'ffr', the fulfill rate\n",
    "        indicator_config: dict, optional\n",
    "            config for calculating trade indicator, including the following fields:\n",
    "            - 'show_indicator': whether to show indicators, optional, default by False. The indicators includes\n",
    "                - 'pa', the price advantage\n",
    "                - 'pos', the positive rate\n",
    "                - 'ffr', the fulfill rate\n",
    "            - 'pa_config': config for calculating price advantage(pa), optional\n",
    "                - 'base_price': the based price than which the trading price is advanced, Optional, default by 'twap'\n",
    "                    - If 'base_price' is 'twap', the based price is the time weighted average price\n",
    "                    - If 'base_price' is 'vwap', the based price is the volume weighted average price\n",
    "                - 'weight_method': weighted method when calculating total trading pa by different orders' pa in each step, optional, default by 'mean'\n",
    "                    - If 'weight_method' is 'mean', calculating mean value of different orders' pa\n",
    "                    - If 'weight_method' is 'amount_weighted', calculating amount weighted average value of different orders' pa\n",
    "                    - If 'weight_method' is 'value_weighted', calculating value weighted average value of different orders' pa\n",
    "            - 'ffr_config': config for calculating fulfill rate(ffr), optional\n",
    "                - 'weight_method': weighted method when calculating total trading ffr by different orders' ffr in each step, optional, default by 'mean'\n",
    "                    - If 'weight_method' is 'mean', calculating mean value of different orders' ffr\n",
    "                    - If 'weight_method' is 'amount_weighted', calculating amount weighted average value of different orders' ffr\n",
    "                    - If 'weight_method' is 'value_weighted', calculating value weighted average value of different orders' ffr\n",
    "            Example:\n",
    "                {\n",
    "                    'show_indicator': True,\n",
    "                    'pa_config': {\n",
    "                        \"agg\": \"twap\",  # \"vwap\"\n",
    "                        \"price\": \"$close\", # default to use deal price of the exchange\n",
    "                    },\n",
    "                    'ffr_config':{\n",
    "                        'weight_method': 'value_weighted',\n",
    "                    }\n",
    "                }\n",
    "        generate_portfolio_metrics : bool, optional\n",
    "            whether to generate portfolio_metrics, by default False\n",
    "        verbose : bool, optional\n",
    "            whether to print trading info, by default False\n",
    "        track_data : bool, optional\n",
    "            whether to generate trade_decision, will be used when training rl agent\n",
    "            - If `self.track_data` is true, when making data for training, the input `trade_decision` of `execute` will be generated by `collect_data`\n",
    "            - Else,  `trade_decision` will not be generated\n",
    "\n",
    "        trade_exchange : Exchange\n",
    "            exchange that provides market info, used to generate portfolio_metrics\n",
    "            - If generate_portfolio_metrics is None, trade_exchange will be ignored\n",
    "            - Else If `trade_exchange` is None, self.trade_exchange will be set with common_infra\n",
    "\n",
    "        common_infra : CommonInfrastructure, optional:\n",
    "            common infrastructure for backtesting, may including:\n",
    "            - trade_account : Account, optional\n",
    "                trade account for trading\n",
    "            - trade_exchange : Exchange, optional\n",
    "                exchange that provides market info\n",
    "\n",
    "        settle_type : str\n",
    "            Please refer to the docs of BasePosition.settle_start\n",
    "        \"\"\"\n",
    "        self.time_per_step = time_per_step\n",
    "        self.indicator_config = indicator_config\n",
    "        self.generate_portfolio_metrics = generate_portfolio_metrics\n",
    "        self.verbose = verbose\n",
    "        self.track_data = track_data\n",
    "        self._trade_exchange = trade_exchange\n",
    "        self.level_infra = LevelInfrastructure()\n",
    "        self.level_infra.reset_infra(common_infra=common_infra)\n",
    "        self._settle_type = settle_type\n",
    "        self.reset(start_time=start_time, end_time=end_time, common_infra=common_infra)\n",
    "        if common_infra is None:\n",
    "            get_module_logger(\"BaseExecutor\").warning(f\"`common_infra` is not set for {self}\")\n",
    "\n",
    "        # record deal order amount in one day\n",
    "        self.dealt_order_amount = defaultdict(float)\n",
    "        self.deal_day = None\n",
    "\n",
    "    def reset_common_infra(self, common_infra, copy_trade_account=False):\n",
    "        \"\"\"\n",
    "        reset infrastructure for trading\n",
    "            - reset trade_account\n",
    "        \"\"\"\n",
    "        if not hasattr(self, \"common_infra\"):\n",
    "            self.common_infra = common_infra\n",
    "        else:\n",
    "            self.common_infra.update(common_infra)\n",
    "\n",
    "        if common_infra.has(\"trade_account\"):\n",
    "            if copy_trade_account:\n",
    "                # NOTE: there is a trick in the code.\n",
    "                # shallow copy is used instead of deepcopy.\n",
    "                # 1. So positions are shared\n",
    "                # 2. Others are not shared, so each level has it own metrics (portfolio and trading metrics)\n",
    "                self.trade_account: Account = copy.copy(common_infra.get(\"trade_account\"))\n",
    "            else:\n",
    "                self.trade_account = common_infra.get(\"trade_account\")\n",
    "            self.trade_account.reset(freq=self.time_per_step, port_metr_enabled=self.generate_portfolio_metrics)\n",
    "\n",
    "    @property\n",
    "    def trade_exchange(self) -> Exchange:\n",
    "        \"\"\"get trade exchange in a prioritized order\"\"\"\n",
    "        return getattr(self, \"_trade_exchange\", None) or self.common_infra.get(\"trade_exchange\")\n",
    "\n",
    "    @property\n",
    "    def trade_calendar(self) -> TradeCalendarManager:\n",
    "        \"\"\"\n",
    "        Though trade calendar can be accessed from multiple sources, but managing in a centralized way will make the\n",
    "        code easier\n",
    "        \"\"\"\n",
    "        return self.level_infra.get(\"trade_calendar\")\n",
    "\n",
    "    def reset(self, common_infra: CommonInfrastructure = None, **kwargs):\n",
    "        \"\"\"\n",
    "        - reset `start_time` and `end_time`, used in trade calendar\n",
    "        - reset `common_infra`, used to reset `trade_account`, `trade_exchange`, .etc\n",
    "        \"\"\"\n",
    "\n",
    "        if \"start_time\" in kwargs or \"end_time\" in kwargs:\n",
    "            start_time = kwargs.get(\"start_time\")\n",
    "            end_time = kwargs.get(\"end_time\")\n",
    "            self.level_infra.reset_cal(freq=self.time_per_step, start_time=start_time, end_time=end_time)\n",
    "        if common_infra is not None:\n",
    "            self.reset_common_infra(common_infra)\n",
    "\n",
    "    def get_level_infra(self):\n",
    "        return self.level_infra\n",
    "\n",
    "    def finished(self):\n",
    "        return self.trade_calendar.finished()\n",
    "\n",
    "    def execute(self, trade_decision: BaseTradeDecision, level: int = 0):\n",
    "        \"\"\"execute the trade decision and return the executed result\n",
    "\n",
    "        NOTE: this function is never used directly in the framework. Should we delete it?\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trade_decision : BaseTradeDecision\n",
    "\n",
    "        level : int\n",
    "            the level of current executor\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        execute_result : List[object]\n",
    "            the executed result for trade decision\n",
    "        \"\"\"\n",
    "        return_value = {}\n",
    "        for _decision in self.collect_data(trade_decision, return_value=return_value, level=level):\n",
    "            pass\n",
    "        return return_value.get(\"execute_result\")\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def _collect_data(cls, trade_decision: BaseTradeDecision, level: int = 0) -> Tuple[List[object], dict]:\n",
    "        \"\"\"\n",
    "        Please refer to the doc of collect_data\n",
    "        The only difference between `_collect_data` and `collect_data` is that some common steps are moved into\n",
    "        collect_data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Please refer to the doc of collect_data\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[List[object], dict]:\n",
    "            (<the executed result for trade decision>, <the extra kwargs for `self.trade_account.update_bar_end`>)\n",
    "        \"\"\"\n",
    "\n",
    "    def collect_data(\n",
    "        self, trade_decision: BaseTradeDecision, return_value: dict = None, level: int = 0\n",
    "    ) -> List[object]:\n",
    "        \"\"\"Generator for collecting the trade decision data for rl training\n",
    "\n",
    "        his function will make a step forward\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trade_decision : BaseTradeDecision\n",
    "\n",
    "        level : int\n",
    "            the level of current executor. 0 indicates the top level\n",
    "\n",
    "        return_value : dict\n",
    "            the mem address to return the value\n",
    "            e.g.  {\"return_value\": <the executed result>}\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        execute_result : List[object]\n",
    "            the executed result for trade decision.\n",
    "            ** NOTE!!!! **:\n",
    "            1) This is necessary,  The return value of generator will be used in NestedExecutor\n",
    "            2) Please note the executed results are not merged.\n",
    "\n",
    "        Yields\n",
    "        -------\n",
    "        object\n",
    "            trade decision\n",
    "        \"\"\"\n",
    "        if self.track_data:\n",
    "            yield trade_decision\n",
    "\n",
    "        atomic = not issubclass(self.__class__, NestedExecutor)  #  issubclass(A, A) is True\n",
    "\n",
    "        if atomic and trade_decision.get_range_limit(default_value=None) is not None:\n",
    "            raise ValueError(\"atomic executor doesn't support specify `range_limit`\")\n",
    "\n",
    "        if self._settle_type != BasePosition.ST_NO:\n",
    "            self.trade_account.current_position.settle_start(self._settle_type)\n",
    "\n",
    "        obj = self._collect_data(trade_decision=trade_decision, level=level)\n",
    "\n",
    "        if isinstance(obj, GeneratorType):\n",
    "            res, kwargs = yield from obj\n",
    "        else:\n",
    "            # Some concrete executor don't have inner decisions\n",
    "            res, kwargs = obj\n",
    "\n",
    "        trade_start_time, trade_end_time = self.trade_calendar.get_step_time()\n",
    "        # Account will not be changed in this function\n",
    "        self.trade_account.update_bar_end(\n",
    "            trade_start_time,\n",
    "            trade_end_time,\n",
    "            self.trade_exchange,\n",
    "            atomic=atomic,\n",
    "            outer_trade_decision=trade_decision,\n",
    "            indicator_config=self.indicator_config,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.trade_calendar.step()\n",
    "\n",
    "        if self._settle_type != BasePosition.ST_NO:\n",
    "            self.trade_account.current_position.settle_commit()\n",
    "\n",
    "        if return_value is not None:\n",
    "            return_value.update({\"execute_result\": res})\n",
    "        return res\n",
    "\n",
    "    def get_all_executors(self):\n",
    "        \"\"\"get all executors\"\"\"\n",
    "        return [self]\n",
    "\n",
    "\n",
    "class NestedExecutor(BaseExecutor):\n",
    "    \"\"\"\n",
    "    Nested Executor with inner strategy and executor\n",
    "    - At each time `execute` is called, it will call the inner strategy and executor to execute the `trade_decision` in a higher frequency env.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_per_step: str,\n",
    "        inner_executor: Union[BaseExecutor, dict],\n",
    "        inner_strategy: Union[BaseStrategy, dict],\n",
    "        start_time: Union[str, pd.Timestamp] = None,\n",
    "        end_time: Union[str, pd.Timestamp] = None,\n",
    "        indicator_config: dict = {},\n",
    "        generate_portfolio_metrics: bool = False,\n",
    "        verbose: bool = False,\n",
    "        track_data: bool = False,\n",
    "        skip_empty_decision: bool = True,\n",
    "        align_range_limit: bool = True,\n",
    "        common_infra: CommonInfrastructure = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inner_executor : BaseExecutor\n",
    "            trading env in each trading bar.\n",
    "        inner_strategy : BaseStrategy\n",
    "            trading strategy in each trading bar\n",
    "        skip_empty_decision: bool\n",
    "            Will the executor skip call inner loop when the decision is empty.\n",
    "            It should be False in following cases\n",
    "            - The decisions may be updated by steps\n",
    "            - The inner executor may not follow the decisions from the outer strategy\n",
    "        align_range_limit: bool\n",
    "            force to align the trade_range decision\n",
    "            It is only for nested executor, because range_limit is given by outer strategy\n",
    "        \"\"\"\n",
    "        self.inner_executor: BaseExecutor = init_instance_by_config(\n",
    "            inner_executor, common_infra=common_infra, accept_types=BaseExecutor\n",
    "        )\n",
    "        self.inner_strategy: BaseStrategy = init_instance_by_config(\n",
    "            inner_strategy, common_infra=common_infra, accept_types=BaseStrategy\n",
    "        )\n",
    "\n",
    "        self._skip_empty_decision = skip_empty_decision\n",
    "        self._align_range_limit = align_range_limit\n",
    "\n",
    "        super(NestedExecutor, self).__init__(\n",
    "            time_per_step=time_per_step,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            indicator_config=indicator_config,\n",
    "            generate_portfolio_metrics=generate_portfolio_metrics,\n",
    "            verbose=verbose,\n",
    "            track_data=track_data,\n",
    "            common_infra=common_infra,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def reset_common_infra(self, common_infra, copy_trade_account=False):\n",
    "        \"\"\"\n",
    "        reset infrastructure for trading\n",
    "            - reset inner_strategyand inner_executor common infra\n",
    "        \"\"\"\n",
    "        # NOTE: please refer to the docs of BaseExecutor.reset_common_infra for the meaning of `copy_trade_account`\n",
    "\n",
    "        # The first level follow the `copy_trade_account` from the upper level\n",
    "        super(NestedExecutor, self).reset_common_infra(common_infra, copy_trade_account=copy_trade_account)\n",
    "\n",
    "        # The lower level have to copy the trade_account\n",
    "        self.inner_executor.reset_common_infra(common_infra, copy_trade_account=True)\n",
    "        self.inner_strategy.reset_common_infra(common_infra)\n",
    "\n",
    "    def _init_sub_trading(self, trade_decision):\n",
    "        trade_start_time, trade_end_time = self.trade_calendar.get_step_time()\n",
    "        self.inner_executor.reset(start_time=trade_start_time, end_time=trade_end_time)\n",
    "        sub_level_infra = self.inner_executor.get_level_infra()\n",
    "        self.level_infra.set_sub_level_infra(sub_level_infra)\n",
    "        self.inner_strategy.reset(level_infra=sub_level_infra, outer_trade_decision=trade_decision)\n",
    "\n",
    "    def _update_trade_decision(self, trade_decision: BaseTradeDecision) -> BaseTradeDecision:\n",
    "        # outer strategy have chance to update decision each iterator\n",
    "        updated_trade_decision = trade_decision.update(self.inner_executor.trade_calendar)\n",
    "        if updated_trade_decision is not None:\n",
    "            trade_decision = updated_trade_decision\n",
    "            # NEW UPDATE\n",
    "            # create a hook for inner strategy to update outer decision\n",
    "            self.inner_strategy.alter_outer_trade_decision(trade_decision)\n",
    "        return trade_decision\n",
    "\n",
    "    def _collect_data(self, trade_decision: BaseTradeDecision, level: int = 0):\n",
    "        execute_result = []\n",
    "        inner_order_indicators = []\n",
    "        decision_list = []\n",
    "        # NOTE:\n",
    "        # - this is necessary to calculating the steps in sub level\n",
    "        # - more detailed information will be set into trade decision\n",
    "        self._init_sub_trading(trade_decision)\n",
    "\n",
    "        _inner_execute_result = None\n",
    "        while not self.inner_executor.finished():\n",
    "            trade_decision = self._update_trade_decision(trade_decision)\n",
    "\n",
    "            if trade_decision.empty() and self._skip_empty_decision:\n",
    "                # give one chance for outer strategy to update the strategy\n",
    "                # - For updating some information in the sub executor(the strategy have no knowledge of the inner\n",
    "                # executor when generating the decision)\n",
    "                break\n",
    "\n",
    "            sub_cal: TradeCalendarManager = self.inner_executor.trade_calendar\n",
    "\n",
    "            # NOTE: make sure get_start_end_idx is after `self._update_trade_decision`\n",
    "            start_idx, end_idx = get_start_end_idx(sub_cal, trade_decision)\n",
    "            if not self._align_range_limit or start_idx <= sub_cal.get_trade_step() <= end_idx:\n",
    "                # if force align the range limit, skip the steps outside the decision range limit\n",
    "\n",
    "                res = self.inner_strategy.generate_trade_decision(_inner_execute_result)\n",
    "\n",
    "                # NOTE: !!!!!\n",
    "                # the two lines below is for a special case in RL\n",
    "                # To solve the confliction below\n",
    "                # - Normally, user will create a strategy and embed it into Qlib's executor and simulator interaction loop\n",
    "                #   For a _nested qlib example_, (Qlib Strategy) <=> (Qlib Executor[(inner Qlib Strategy) <=> (inner Qlib Executor)])\n",
    "                # - However, RL-based framework has it's own script to run the loop\n",
    "                #   For an _RL learning example_, (RL Policy) <=> (RL Env[(inner Qlib Executor)])\n",
    "                # To make it possible to run  _nested qlib example_ and _RL learning example_ together, the solution below is proposed\n",
    "                # - The entry script follow the example of  _RL learning example_ to be compatible with all kinds of RL Framework\n",
    "                # - Each step of (RL Env) will make (inner Qlib Executor) one step forward\n",
    "                #     - (inner Qlib Strategy) is a proxy strategy, it will give the program control right to (RL Env) by `yield from` and wait for the action from the policy\n",
    "                # So the two lines below is the implementation of yielding control rights\n",
    "                if isinstance(res, GeneratorType):\n",
    "                    res = yield from res\n",
    "\n",
    "                _inner_trade_decision: BaseTradeDecision = res\n",
    "\n",
    "                trade_decision.mod_inner_decision(_inner_trade_decision)  # propagate part of decision information\n",
    "\n",
    "                # NOTE sub_cal.get_step_time() must be called before collect_data in case of step shifting\n",
    "                decision_list.append((_inner_trade_decision, *sub_cal.get_step_time()))\n",
    "\n",
    "                # NOTE: Trade Calendar will step forward in the follow line\n",
    "                _inner_execute_result = yield from self.inner_executor.collect_data(\n",
    "                    trade_decision=_inner_trade_decision, level=level + 1\n",
    "                )\n",
    "                self.post_inner_exe_step(_inner_execute_result)\n",
    "                execute_result.extend(_inner_execute_result)\n",
    "\n",
    "                inner_order_indicators.append(\n",
    "                    self.inner_executor.trade_account.get_trade_indicator().get_order_indicator(raw=True)\n",
    "                )\n",
    "            else:\n",
    "                # do nothing and just step forward\n",
    "                sub_cal.step()\n",
    "\n",
    "        return execute_result, {\"inner_order_indicators\": inner_order_indicators, \"decision_list\": decision_list}\n",
    "\n",
    "    def post_inner_exe_step(self, inner_exe_res):\n",
    "        \"\"\"\n",
    "        A hook for doing sth after each step of inner strategy\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inner_exe_res :\n",
    "            the execution result of inner task\n",
    "        \"\"\"\n",
    "\n",
    "    def get_all_executors(self):\n",
    "        \"\"\"get all executors, including self and inner_executor.get_all_executors()\"\"\"\n",
    "        return [self, *self.inner_executor.get_all_executors()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_infra = LevelInfrastructure()\n",
    "print(type(level_infra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_infra.get_support_infra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_support_infra = level_infra.get_support_infra()\n",
    "get_support_infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_infra.reset_cal(\"day\", \"2021-05-20\", \"2021-06-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_infra.set_sub_level_infra(sub_level_infra = LevelInfrastructure())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = model.predict(dataset)\n",
    "from qlib.contrib.strategy.signal_strategy import create_signal_from\n",
    "sgl = create_signal_from(sl)\n",
    "tk = WeekTopkDropoutStrategy(signal = sgl, risk_degree = 0.95,common_infra=common_infra, topk = 50, \n",
    "                         n_drop = 5, method_sell=\"bottom\", method_buy=\"top\", level_infra = level_infra,\n",
    "                         hold_thresh=1, only_tradable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WO = tk.generate_trade_decision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caf831573a0ff294614842876d2763885d6da16fb80bd95fae4076843946dd1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
